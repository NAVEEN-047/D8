{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 : Performance measurements of LR and DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library packages\n",
    "import pandas as p\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as s\n",
    "import numpy as n\n",
    "#read the given dataset\n",
    "df = p.read_csv(\"df4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Mean Temp':'T'}, inplace=True)\n",
    "df.rename(columns={'Average Humidity':'H'}, inplace=True)\n",
    "df.rename(columns={'rainfall':'R'}, inplace=True)\n",
    "df.rename(columns={'Cost of Cultivation (`/Hectare) C2':'CC'}, inplace=True)\n",
    "df.rename(columns={'Cost of Production (`/Quintal) C2':'CP'}, inplace=True)\n",
    "df.rename(columns={'Yield (Quintal/ Hectare) ':'Y'}, inplace=True)\n",
    "df.rename(columns={'cost of production per yield':'CPPY'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Y']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)\n",
    "df['YPr']= df.Y.map({'13':0, '7':0, '11':0, '4':0, '23':0, '39':1, '10':0, '18':0, '36':1, '47':1, '8':0, '3':0,\n",
    "       '38':1, '46':1, '5':0, '9':0, '2':0, '44':1, '17':0, '41':1, '6':0, '16':0, '35':1, '19':0,\n",
    "       '0':0, '43':1, '12':0, '45':1, '25':0, '33':1, '29':0, '37':1, '32':1, '21':0, '42':1,\n",
    "       '48':1, '30':1, '34':1, '26':0, '20':0, '31':1, '24':0, '27':0, '22':0, '40':1, '28':0,\n",
    "       '1':0, '14':0, '15':0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State_Name', 'District_Name', 'Crop_Year', 'Season', 'Crop', 'Area',\n",
       "       'R', 'H', 'T', 'CC', 'CP', 'Y', 'CPPY', 'YPr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>District_Name</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>T</th>\n",
       "      <th>CC</th>\n",
       "      <th>CP</th>\n",
       "      <th>Y</th>\n",
       "      <th>CPPY</th>\n",
       "      <th>YPr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1016</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>172</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_Name District_Name Crop_Year Season Crop  Area    R   H   T  CC  CP  \\\n",
       "0          0            42         3      0    0  1015   33  45  10  21  30   \n",
       "1          0            42         4      0    0  1015  121  44   6   3  26   \n",
       "2          0            42         5      3    0  1016  118  46   1  33  45   \n",
       "3          0            42         6      3    0  1018  172  45   6   4  36   \n",
       "4          0            42         7      3    0  1019   75  51  15  20  24   \n",
       "\n",
       "    Y CPPY  YPr  \n",
       "0   5  126    0  \n",
       "1  46   72    0  \n",
       "2   3  200    0  \n",
       "3  34   78    0  \n",
       "4  16  144    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['State_Name', 'District_Name', 'Crop_Year', 'Season', 'Crop', 'Area',\n",
    "       'R', 'H', 'T', 'CC', 'CP', 'Y','CPPY']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Crop by yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='YPr', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'YPr']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1776\n",
      "           1       0.95      0.94      0.95      1087\n",
      "\n",
      "    accuracy                           0.96      2863\n",
      "   macro avg       0.96      0.96      0.96      2863\n",
      "weighted avg       0.96      0.96      0.96      2863\n",
      "\n",
      "Accuracy result of Logistic Regression is: 95.87844917918268\n",
      "\n",
      "Confusion Matrix result of Logistic Regression is:\n",
      " [[1724   52]\n",
      " [  66 1021]]\n",
      "\n",
      "Sensitivity :  0.9707207207207207\n",
      "\n",
      "Specificity :  0.9392824287028518\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logR= LogisticRegression()\n",
    "\n",
    "logR.fit(X_train,y_train)\n",
    "\n",
    "predictR = logR.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "x = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of Logistic Regression is:', x)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 1021\n",
      "True Negative : 1724\n",
      "False Positive : 52\n",
      "False Negative : 66\n",
      "\n",
      "True Positive Rate : 0.9392824287028518\n",
      "True Negative Rate : 0.9707207207207207\n",
      "False Positive Rate : 0.02927927927927928\n",
      "False Negative Rate : 0.06071757129714812\n",
      "\n",
      "Positive Predictive Value : 0.9515377446411929\n",
      "Negative predictive value : 0.9631284916201117\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Decision Tree Classifier Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1776\n",
      "           1       1.00      1.00      1.00      1087\n",
      "\n",
      "    accuracy                           1.00      2863\n",
      "   macro avg       1.00      1.00      1.00      2863\n",
      "weighted avg       1.00      1.00      1.00      2863\n",
      "\n",
      "Accuracy result of Decision Tree Classifier is 100.0\n",
      "\n",
      "Confusion Matrix result of Decision Tree Classifier is:\n",
      " [[1776    0]\n",
      " [   0 1087]]\n",
      "\n",
      "Sensitivity :  1.0\n",
      "\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "predictDT = dtree.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Classifier Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictDT))\n",
    "x = (accuracy_score(y_test,predictDT)*100)\n",
    "\n",
    "print('Accuracy result of Decision Tree Classifier is', x)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictDT)\n",
    "print('Confusion Matrix result of Decision Tree Classifier is:\\n', confusion_matrix(y_test,predictDT))\n",
    "print(\"\")\n",
    "\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 1087\n",
      "True Negative : 1776\n",
      "False Positive : 0\n",
      "False Negative : 0\n",
      "\n",
      "True Positive Rate : 1.0\n",
      "True Negative Rate : 1.0\n",
      "False Positive Rate : 0.0\n",
      "False Negative Rate : 0.0\n",
      "\n",
      "Positive Predictive Value : 1.0\n",
      "Negative predictive value : 1.0\n"
     ]
    }
   ],
   "source": [
    "TN = cm2[0][0]\n",
    "FN = cm2[1][0]\n",
    "TP = cm2[1][1]\n",
    "FP = cm2[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Crop by Cost production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['CPPY']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)\n",
    "df['CPPYPr']= df.CPPY.map({'126':0, '72':0, '200':0, '78':0, '144':0, '212':0, '149':0, '151':0, '178':0, '312':0,\n",
    "       '187':0, '69':0, '205':0, '276':1, '76':0, '134':0, '66':0, '254':1, '150':0, '291':1,\n",
    "       '155':0, '106':0, '87':0, '119':0, '183':0, '170':0, '28':0, '265':1, '180':0, '36':0,\n",
    "       '293':1, '326':1, '148':0, '234':1, '3':0, '124':0, '111':0, '182':0, '166':0, '169':0,\n",
    "       '270':1, '243':1, '98':0, '230':0, '282':1, '334':1, '188':0, '65':0, '34':0, '328':1,\n",
    "       '160':0, '115':0, '89':0, '152':0, '240':1, '141':0, '233':1, '32':0, '281':1, '335':1,\n",
    "       '109':0, '47':0, '136':0, '112':0, '261':1, '229':0, '42':0, '325':1, '213':0, '175':0,\n",
    "       '125':0, '196':0, '292':1, '82':0, '235':1, '79':0, '105':0, '123':0, '210':0, '39':0,\n",
    "       '146':0, '185':0, '201':0, '41':0, '164':0, '184':0, '222':0, '250':0, '301':1,\n",
    "       '218':0, '217':0, '168':0, '264':1, '46':0, '103':0, '284':1, '198':0, '56':0, '171':0,\n",
    "       '331':1, '256':1, '99':0, '58':0, '247':1, '286':1, '67':0, '133':0, '143':0, '204':0,\n",
    "       '227':0, '194':0, '6':0, '280':1, '225':0, '48':0, '258':1, '94':0, '244':1, '294':1,\n",
    "       '215':0, '132':0, '277':1, '71':0, '219':0, '315':1, '97':0, '91':0, '156':0, '289':1,\n",
    "       '100':0, '295':1, '147':0, '214':0, '19':0, '223':0, '90':0, '269':1, '300':1, '114':0,\n",
    "       '135':0, '173':0, '55':0, '113':0, '127':0, '73':0, '177':0, '274':1, '118':0, '191':0,\n",
    "       '145':0, '307':1, '162':0, '228':0, '50':0, '5':0, '248':1, '203':0, '61':0, '129':0,\n",
    "       '192':0, '83':0, '158':0, '206':0, '242':1, '267':1, '137':0, '92':0, '176':0, '298':1,\n",
    "       '25':0, '296':1, '186':0, '239':1, '193':0, '165':0, '310':1, '20':0, '287':1, '75':0,\n",
    "       '107':0, '271':1, '138':0, '121':0, '241':1, '74':0, '43':0, '232':0, '154':0, '181':0,\n",
    "       '195':0, '102':0, '237':1, '110':0, '268':1, '49':0, '104':0, '64':0, '318':1, '13':0,\n",
    "       '128':0, '153':0, '31':0, '93':0, '309':1, '257':0, '52':0, '262':1, '202':0, '174':0,\n",
    "       '101':0, '224':0, '86':0, '45':0, '263':1, '167':0, '17':0, '29':0, '30':0, '54':0,\n",
    "       '303':1, '163':0, '251':1, '142':0, '273':1, '96':0, '35':0, '327':1, '53':0, '15':0,\n",
    "       '190':0, '308':1, '226':0, '139':0, '62':0, '2':0, '1':0, '27':0, '84':0, '285':1,\n",
    "       '246':1, '23':0, '189':0, '299':1, '231':0, '24':0, '16':0, '333':1, '306':1, '18':0,\n",
    "       '288':1, '199':0, '260':1, '323':1, '37':0, '278':1, '324':1, '140':0, '4':0, '245':1,\n",
    "       '322':1, '329':1, '159':0, '80':0, '197':0, '275':1, '11':0, '40':0, '33':0, '0':0,\n",
    "       '320':1, '290':1, '68':0, '220':0, '21':0, '330':1, '12':0, '157':0, '302':1, '44':0,\n",
    "       '221':0, '216':0, '279':1, '63':0, '313':1, '311':1, '332':1, '266':1, '238':1,\n",
    "       '211':0, '172':0, '14':0, '117':0, '161':0, '122':0, '60':0, '321':1, '95':0, '208':0,\n",
    "       '272':1, '131':0, '207':0, '81':0, '314':1, '51':0, '283':1, '120':0, '38':0, '9':0,\n",
    "       '130':0, '70':0, '179':0, '7':0, '10':0, '108':0, '255':1, '77':0, '88':0, '22':0,\n",
    "       '57':0, '85':0, '304':1, '253':1, '249':0, '297':1, '116':0, '305':1, '317':1, '252':1,\n",
    "       '236':1, '209':0, '259':1, '26':0, '319':1, '316':1, '59':0, '336':1, '8':0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>District_Name</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>T</th>\n",
       "      <th>CC</th>\n",
       "      <th>CP</th>\n",
       "      <th>Y</th>\n",
       "      <th>CPPY</th>\n",
       "      <th>YPr</th>\n",
       "      <th>CPPYPr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>141</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>82</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>187</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State_Name District_Name Crop_Year Season Crop Area    R   H   T  CC  CP  \\\n",
       "0          0            37        11      0    0   20  141  40   2  14  24   \n",
       "1          0            37        12      0    0   20   26  39  44  23  19   \n",
       "2          0            37        13      3    0   21   22  41   1  27  40   \n",
       "3          0            37        14      3    0   23   82  40  44  34  30   \n",
       "4          0            37        15      3    0   24  187  47   7  13  17   \n",
       "\n",
       "    Y CPPY  YPr  CPPYPr  \n",
       "0  44  235    0       0  \n",
       "1  41  232    0       1  \n",
       "2  23   18    0       0  \n",
       "3  28  239    0       1  \n",
       "4   8  284    0       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['State_Name', 'District_Name', 'Crop_Year', 'Season', 'Crop', 'Area',\n",
    "       'R', 'H', 'T', 'CC', 'CP', 'Y','CPPY']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='CPPYPr', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'CPPYPr']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1986\n",
      "           1       0.33      0.15      0.21       877\n",
      "\n",
      "    accuracy                           0.64      2863\n",
      "   macro avg       0.51      0.51      0.49      2863\n",
      "weighted avg       0.58      0.64      0.60      2863\n",
      "\n",
      "Accuracy result of Logistic Regression is: 64.40796367446734\n",
      "\n",
      "Confusion Matrix result of Logistic Regression is:\n",
      " [[1710  276]\n",
      " [ 743  134]]\n",
      "\n",
      "Sensitivity :  0.8610271903323263\n",
      "\n",
      "Specificity :  0.15279361459521096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logR= LogisticRegression()\n",
    "\n",
    "logR.fit(X_train,y_train)\n",
    "\n",
    "predictR = logR.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "x = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of Logistic Regression is:', x)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 134\n",
      "True Negative : 1710\n",
      "False Positive : 276\n",
      "False Negative : 743\n",
      "\n",
      "True Positive Rate : 0.15279361459521096\n",
      "True Negative Rate : 0.8610271903323263\n",
      "False Positive Rate : 0.13897280966767372\n",
      "False Negative Rate : 0.8472063854047891\n",
      "\n",
      "Positive Predictive Value : 0.32682926829268294\n",
      "Negative predictive value : 0.6971055849979617\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Decision Tree Classifier Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1986\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      2863\n",
      "   macro avg       1.00      1.00      1.00      2863\n",
      "weighted avg       1.00      1.00      1.00      2863\n",
      "\n",
      "Accuracy result of Decision Tree Classifier is 100.0\n",
      "\n",
      "Confusion Matrix result of Decision Tree Classifier is:\n",
      " [[1986    0]\n",
      " [   0  877]]\n",
      "\n",
      "Sensitivity :  1.0\n",
      "\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "predictDT = dtree.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Classifier Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictDT))\n",
    "x = (accuracy_score(y_test,predictDT)*100)\n",
    "\n",
    "print('Accuracy result of Decision Tree Classifier is', x)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictDT)\n",
    "print('Confusion Matrix result of Decision Tree Classifier is:\\n', confusion_matrix(y_test,predictDT))\n",
    "print(\"\")\n",
    "\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 877\n",
      "True Negative : 1986\n",
      "False Positive : 0\n",
      "False Negative : 0\n",
      "\n",
      "True Positive Rate : 1.0\n",
      "True Negative Rate : 1.0\n",
      "False Positive Rate : 0.0\n",
      "False Negative Rate : 0.0\n",
      "\n",
      "Positive Predictive Value : 1.0\n",
      "Negative predictive value : 1.0\n"
     ]
    }
   ],
   "source": [
    "TN = cm2[0][0]\n",
    "FN = cm2[1][0]\n",
    "TP = cm2[1][1]\n",
    "FP = cm2[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
